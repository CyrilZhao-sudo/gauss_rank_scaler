{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_preprocessing.gauss_rank_scaler import *\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch = load_boston()\n",
    "\n",
    "y_train = bunch.target[:250]\n",
    "y_test = bunch.target[250:]\n",
    "\n",
    "X_train = pd.DataFrame(bunch.data[:250], columns=bunch.feature_names)\n",
    "X_test = pd.DataFrame(bunch.data[250:], columns=bunch.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X_train[['CRIM', 'DIS']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_rank_scaler = GuassRankScaler()\n",
    "X_train_new = gauss_rank_scaler.fit_transform(X_train[['CRIM', 'DIS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = pd.DataFrame(X_train_new, columns=['CRIM', 'DIS']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gauss_rank_scaler.inverse_transform(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = pd.DataFrame(a, columns=['CRIM', 'DIS']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X_train[['CRIM', 'RM', 'AGE', 'DIS', 'B', 'LSTAT']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class GuassRankScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Standardize features by removing the mean and scaling to unit variance\n",
    "        The standard score of a sample `x` is calculated as:\n",
    "            z = (x - u) / s\n",
    "        where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
    "        and `s` is the standard deviation of the training samples or one if\n",
    "        `with_std=False`.\n",
    "        Centering and scaling happen independently on each feature by computing\n",
    "        the relevant statistics on the samples in the training set. Mean and\n",
    "        standard deviation are then stored to be used on later data using the\n",
    "        `transform` method.\n",
    "        Standardization of a dataset is a common requirement for many\n",
    "        machine learning estimators: they might behave badly if the\n",
    "        individual features do not more or less look like standard normally\n",
    "        distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
    "        For instance many elements used in the objective function of\n",
    "        a learning algorithm (such as the RBF kernel of Support Vector\n",
    "        Machines or the L1 and L2 regularizers of linear models) assume that\n",
    "        all features are centered around 0 and have variance in the same\n",
    "        order. If a feature has a variance that is orders of magnitude larger\n",
    "        that others, it might dominate the objective function and make the\n",
    "        estimator unable to learn from other features correctly as expected.\n",
    "        This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
    "        `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
    "        Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        copy : boolean, optional, default True\n",
    "            If False, try to avoid a copy and do inplace scaling instead.\n",
    "            This is not guaranteed to always work inplace; e.g. if the data is\n",
    "            not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
    "            returned.\n",
    "        with_mean : boolean, True by default\n",
    "            If True, center the data before scaling.\n",
    "            This does not work (and will raise an exception) when attempted on\n",
    "            sparse matrices, because centering them entails building a dense\n",
    "            matrix which in common use cases is likely to be too large to fit in\n",
    "            memory.\n",
    "        with_std : boolean, True by default\n",
    "            If True, scale the data to unit variance (or equivalently,\n",
    "            unit standard deviation).\n",
    "        Attributes\n",
    "        ----------\n",
    "        scale_ : ndarray or None, shape (n_features,)\n",
    "            Per feature relative scaling of the data. This is calculated using\n",
    "            `np.sqrt(var_)`. Equal to ``None`` when ``with_std=False``.\n",
    "            .. versionadded:: 0.17\n",
    "               *scale_*\n",
    "        mean_ : ndarray or None, shape (n_features,)\n",
    "            The mean value for each feature in the training set.\n",
    "            Equal to ``None`` when ``with_mean=False``.\n",
    "        var_ : ndarray or None, shape (n_features,)\n",
    "            The variance for each feature in the training set. Used to compute\n",
    "            `scale_`. Equal to ``None`` when ``with_std=False``.\n",
    "        n_samples_seen_ : int or array, shape (n_features,)\n",
    "            The number of samples processed by the estimator for each feature.\n",
    "            If there are not missing samples, the ``n_samples_seen`` will be an\n",
    "            integer, otherwise it will be an array.\n",
    "            Will be reset on new calls to fit, but increments across\n",
    "            ``partial_fit`` calls.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-4, copy=True, n_jobs=None, interp_kind='linear', interp_copy=False):\n",
    "        self.epsilon = epsilon\n",
    "        self.copy = copy\n",
    "        self.interp_params = {'kind': interp_kind, 'copy': interp_copy, 'fill_value': 'extrapolate'}\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute the mean and std to be used for later scaling.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to compute the mean and standard deviation\n",
    "            used for later scaling along the features axis.\n",
    "        y\n",
    "            Ignored\n",
    "        \"\"\"\n",
    "        X = check_array(X, copy=self.copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        ranks = np.argsort(np.argsort(X, axis=0), axis=0)\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factors = np.max(ranks) / 2.0 * bound\n",
    "        scaled_ranks = np.clip(ranks / factors - bound, -bound, bound)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._fit)(x) for x in X.T)\n",
    "        return self\n",
    "    \n",
    "    def _fit(self, x):\n",
    "        x = self.drop_duplicates(x)\n",
    "        rank = np.argsort(np.argsort(x))\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factor = np.max(rank) / 2.0 * bound\n",
    "        scaled_rank = np.clip(rank / factor - bound, -bound, bound)\n",
    "        return interp1d(x, scaled_rank, **self.interp_params)\n",
    "        \n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Perform standardization by centering and scaling\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Scale back the data to the original representation\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, **self.interp_params)\n",
    "        return inv_interp_func(erf(x))\n",
    "    \n",
    "    def drop_duplicates(self, x):\n",
    "        m = np.zeros_like(x, dtype=bool)\n",
    "        m[np.unique(x, return_index=True)[1]] = True\n",
    "        return x[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(x):\n",
    "    m = np.zeros_like(x, dtype=bool)\n",
    "    m[np.unique(x, return_index=True)[1]] = True\n",
    "    return x[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 1, 3, 3, 3, 0])\n",
    "m = np.zeros_like(a, dtype=bool)\n",
    "m[np.unique(a, return_index=True)[1]] = True\n",
    "a[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a, return_index=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_rank_scaler = GuassRankScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = drop_duplicates(X_train['ZN'])\n",
    "rank = np.argsort(np.argsort(x))\n",
    "bound = 1.0 - 0.0001\n",
    "factor = np.max(rank) / 2.0 * bound\n",
    "scaled_rank = np.clip(rank / factor - bound, -bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gauss_rank_scaler.fit_transform(X_train[['CRIM', 'ZN', 'RM', 'AGE', 'DIS', 'B', 'LSTAT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort([1.0, 3.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfinv\n",
    "\n",
    "class GaussRankScaler():\n",
    "\n",
    "\tdef __init__( self ):\n",
    "\t\tself.epsilon = 0.001\n",
    "\t\tself.lower = -1 + self.epsilon\n",
    "\t\tself.upper =  1 - self.epsilon\n",
    "\t\tself.range = self.upper - self.lower\n",
    "\n",
    "\tdef fit_transform( self, X ):\n",
    "\t\n",
    "\t\ti = np.argsort( X, axis = 0 )\n",
    "\t\tj = np.argsort( i, axis = 0 )\n",
    "\n",
    "\t\tassert ( j.min() == 0 ).all()\n",
    "\t\tassert ( j.max() == len( j ) - 1 ).all()\n",
    "\t\t\n",
    "\t\tj_range = len( j ) - 1\n",
    "\t\tself.divider = j_range / self.range\n",
    "\t\t\n",
    "\t\ttransformed = j / self.divider\n",
    "\t\ttransformed = transformed - self.upper\n",
    "\t\ttransformed = erfinv( transformed )\n",
    "\t\t\n",
    "\t\treturn transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rankgauss_trafo(x):\n",
    "    finite_indices = np.isfinite(x)\n",
    "    if np.sum(finite_indices) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    x_finite = x[np.isfinite(x)]\n",
    " \n",
    "    hist = dict()\n",
    "    for val in x_finite:\n",
    "        hist[val] = hist.get(val, 0) + 1\n",
    " \n",
    "    len_hist = len(hist)\n",
    "    list_keys = list(hist.keys())\n",
    " \n",
    "    if len_hist == 1:\n",
    "        return np.array(list_keys), np.array([0.0])\n",
    "    elif len_hist == 2:\n",
    "        return np.array(list_keys), np.array([0.0, 1.0])\n",
    "    else:\n",
    "        hist = OrderedDict(sorted(hist.items()))    # sort by key\n",
    "        n = float(x_finite.shape[0])\n",
    "        cnt = 0.0\n",
    "        mean = 0.0\n",
    "        trafo_keys = list()\n",
    "        trafo_values = list()\n",
    " \n",
    "        for key, val in hist.items():\n",
    "            # (notice) 'cnt / n * 0.998 + 1e-3' is always larger than zero\n",
    "            rank_v = norm_cdf_inv(cnt / n * 0.998 + 1e-3) * 0.7\n",
    "            trafo_keys.append(key)\n",
    "            trafo_values.append(rank_v)\n",
    "            mean += val * rank_v\n",
    "            cnt += val\n",
    " \n",
    "        mean /= n\n",
    "        trafo_values = np.array(trafo_values)\n",
    "        trafo_values -= mean\n",
    " \n",
    "        return np.array(trafo_keys), trafo_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class GuassRankScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, epsilon=1e-4, kind='linear', copy=False, n_jobs=None):\n",
    "        self.epsilon = epsilon\n",
    "        self.interp_params = {'kind': kind, 'copy': copy, 'fill_value': 'extrapolate'}\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = check_array(X, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        ranks = np.argsort(np.argsort(X, axis=0), axis=0)\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factors = np.max(ranks) / 2.0 * bound\n",
    "        scaled_ranks = np.clip(ranks / factors - bound, -bound, bound)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(interp1d)(x, r, **self.interp_params) for x, r in zip(X.T, scaled_ranks.T))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "        X = check_array(X, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "        X = check_array(X, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, **self.interp_params)\n",
    "        return inv_interp_func(erf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GuassRankScaler(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_train[['CRIM', 'RM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = check_array(X_tr, dtype=FLOAT_DTYPES, force_all_finite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = np.argsort(np.argsort(X_v, axis=0), axis=0)\n",
    "bound = 1.0 - 0.0001\n",
    "factors = np.max(ranks) / 2.0 * bound\n",
    "scaled_ranks = np.clip(ranks / factors - bound, -bound, bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for x, r in zip(X_v.T, scaled_ranks.T):\n",
    "    a.append(interp1d(x, r, **interp_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_params = {'kind': 'linear', 'copy': False, 'fill_value': 'extrapolate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func_ = Parallel(n_jobs=None)(\n",
    "    delayed(interp1d)(x, r, **interp_params) for x, r in (X_v.T, scaled_ranks.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform(i, x):\n",
    "    return interp_func_[i](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func_[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=None)(delayed(_transform)(i, x) for i, x in enumerate(X_v.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.interp_func_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = np.argsort(np.argsort(X_tr, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bound = 1.0 - 0.001\n",
    "factor = np.max(ranks) / 2.0 * bound\n",
    "scaled_ranks = np.clip(ranks / factor - bound, -bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = [(x, y) for x, y in (X_tr.values.T, scaled_ranks.values.T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func = interp1d(X_tr, scaled_ranks, kind='linear', fill_value='extrapolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = interp_func(X_train['CRIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = scaler.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CRIM'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(z).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scaler.fit_transform(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(vv[:, 0]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CRIM'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(v).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CRIM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(v.shape[0])[~np.isfinite(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = a[a != np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = scaler.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import FLOAT_DTYPES, check_is_fitted\n",
    "from sklearn.utils import check_array, check_random_state\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import OrderedDict\n",
    "from numba import jit\n",
    " \n",
    " \n",
    "try:\n",
    "    from joblib import Parallel, delayed\n",
    "except ImportError:\n",
    "    from sklearn.externals.joblib import Parallel, delayed\n",
    " \n",
    " \n",
    "class RankGaussScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nan_to_val=None, extrapolate=False, num_storing=None,\n",
    "                 random_state=None, interp_params=None, n_jobs=None):\n",
    "        nan_to_val = nan_to_val or True\n",
    "        self.nan_to_val = 0.0 if isinstance(nan_to_val, bool) else nan_to_val\n",
    "        self.force_all_finite = False\n",
    "        if isinstance(nan_to_val, bool) and not nan_to_val:\n",
    "            self.force_all_finite = True\n",
    " \n",
    "        self.extrapolate = extrapolate\n",
    "        num_storing = num_storing or np.iinfo(int).max\n",
    "        self.num_storing = 2 if num_storing < 2 else num_storing\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.interp_params = interp_params or dict(kind='linear')\n",
    "        self.n_jobs = n_jobs\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        X = self._check_array(X)\n",
    "        X = self._to_2d_if_1d(X)\n",
    " \n",
    "        self.codebooks_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._make_codebook)(*x) for x in enumerate(X.T))\n",
    " \n",
    "        return self\n",
    " \n",
    "    def transform(self, X):\n",
    "        transformed = self._transform(X, self._transform_column)\n",
    "        if not self.force_all_finite:\n",
    "            transformed[~np.isfinite(transformed)] = self.nan_to_val\n",
    "        return transformed\n",
    " \n",
    "    def inverse_transform(self, X):\n",
    "        return self._transform(X, self._inv_transform_column)\n",
    " \n",
    "    def _transform(self, X, func_transform):\n",
    "        X = self._check_before_transform(X)\n",
    "        return_as_1d = True if len(X.shape) == 1 else False\n",
    "        X = self._to_2d_if_1d(X)\n",
    " \n",
    "        transformed = np.array(\n",
    "            Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(func_transform)(*x, **self.interp_params)\n",
    "                for x in enumerate(X.T))).T\n",
    " \n",
    "        return self._to_1d_if_single(transformed) if return_as_1d \\\n",
    "            else transformed    # preserve input shape\n",
    " \n",
    "    def _check_array(self, X):\n",
    "        # validate input and return X as numpy format\n",
    "        return check_array(X, dtype=FLOAT_DTYPES, ensure_2d=False,\n",
    "                           force_all_finite=self.force_all_finite)\n",
    " \n",
    "    def _check_num_cols(self, X):\n",
    "        # validate input after fit()\n",
    "        num_features = 1 if len(X.shape) == 1 else X.shape[1]\n",
    "        if num_features != len(self.codebooks_):\n",
    "            raise ValueError('bad input shape {0}'.format(X.shape))\n",
    " \n",
    "    def _check_before_transform(self, X):\n",
    "        check_is_fitted(self, 'codebooks_')    # check if 'codebooks_' exists\n",
    "        X = self._check_array(X)       # check input type and structure\n",
    "        self._check_num_cols(X)        # check # of columns\n",
    "        return X\n",
    " \n",
    "    def _make_codebook(self, col_index, x):\n",
    "        codebook = build_rankgauss_trafo(x)\n",
    "        num_codes = len(codebook[0])\n",
    " \n",
    "        if num_codes == 0:\n",
    "            raise ValueError('column %d contains only null values' % col_index)\n",
    "        elif num_codes > self.num_storing:\n",
    "            # first, select minimum and maximum, then choose the rest randomly\n",
    "            chosen = self.random_state.choice(\n",
    "                num_codes - 2, self.num_storing - 2, replace=False)\n",
    "            chosen = np.append(np.array([0, num_codes - 1]), chosen + 1)\n",
    "            return codebook[0][chosen], codebook[1][chosen]\n",
    "        else:\n",
    "            return codebook\n",
    " \n",
    "    def _transform_column(self, index, x, **interp1d_params):\n",
    "        return self._transform_with_interp(\n",
    "            x, *self.codebooks_[index], **interp1d_params)\n",
    " \n",
    "    def _inv_transform_column(self, index, x, **interp1d_params):\n",
    "        return self._transform_with_interp(\n",
    "            x, *reversed(self.codebooks_[index]), **interp1d_params)\n",
    " \n",
    "    def _transform_with_interp(self, x, train_x, train_y, **interp1d_params):\n",
    "        if len(train_x) == 1:\n",
    "            return np.ones(x.shape) * train_y[0]\n",
    "        f = interp1d(train_x, train_y, fill_value='extrapolate',\n",
    "                     **interp1d_params)\n",
    "        return f(x) if self.extrapolate else f(np.clip(x, *minmax(train_x)))\n",
    " \n",
    "    @staticmethod\n",
    "    def _to_2d_if_1d(a):\n",
    "        return a.reshape(-1, 1) if len(a.shape) == 1 else a\n",
    " \n",
    "    @staticmethod\n",
    "    def _to_1d_if_single(a):\n",
    "        return a.ravel() if a.shape[1] == 1 else a\n",
    " \n",
    " \n",
    "# function for simultaneous max() and min() (using numba)\n",
    "# https://stackoverflow.com/a/33919126\n",
    "@jit\n",
    "def minmax(x):\n",
    "    maximum = x[0]\n",
    "    minimum = x[0]\n",
    "    for i in x[1:]:\n",
    "        if i > maximum:\n",
    "            maximum = i\n",
    "        elif i < minimum:\n",
    "            minimum = i\n",
    "    return minimum, maximum\n",
    " \n",
    " \n",
    "# converted from [ref 1]\n",
    "@jit\n",
    "def norm_cdf_inv(p):\n",
    "    sign = 1.0\n",
    "    if p < 0.5:\n",
    "        sign = -1.0\n",
    "    else:\n",
    "        p = 1.0 - p\n",
    "    t = np.sqrt(-2.0 * np.log(p))\n",
    "    return sign * (t - ((0.010328 * t + 0.802853) * t + 2.515517) /\n",
    "                   (((0.001308 * t + 0.189269) * t + 1.432788) * t + 1.0))\n",
    " \n",
    " \n",
    "# converted from [ref 1]\n",
    "@jit\n",
    "def build_rankgauss_trafo(x):\n",
    "    finite_indices = np.isfinite(x)\n",
    "    if np.sum(finite_indices) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    x_finite = x[np.isfinite(x)]\n",
    " \n",
    "    hist = dict()\n",
    "    for val in x_finite:\n",
    "        hist[val] = hist.get(val, 0) + 1\n",
    " \n",
    "    len_hist = len(hist)\n",
    "    list_keys = list(hist.keys())\n",
    " \n",
    "    if len_hist == 1:\n",
    "        return np.array(list_keys), np.array([0.0])\n",
    "    elif len_hist == 2:\n",
    "        return np.array(list_keys), np.array([0.0, 1.0])\n",
    "    else:\n",
    "        hist = OrderedDict(sorted(hist.items()))    # sort by key\n",
    "        n = float(x_finite.shape[0])\n",
    "        cnt = 0.0\n",
    "        mean = 0.0\n",
    "        trafo_keys = list()\n",
    "        trafo_values = list()\n",
    " \n",
    "        for key, val in hist.items():\n",
    "            # (notice) 'cnt / n * 0.998 + 1e-3' is always larger than zero\n",
    "            rank_v = norm_cdf_inv(cnt / n * 0.998 + 1e-3) * 0.7\n",
    "            trafo_keys.append(key)\n",
    "            trafo_values.append(rank_v)\n",
    "            mean += val * rank_v\n",
    "            cnt += val\n",
    " \n",
    "        mean /= n\n",
    "        trafo_values = np.array(trafo_values)\n",
    "        trafo_values -= mean\n",
    " \n",
    "        return np.array(trafo_keys), trafo_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussrankscaler = GaussRankScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "v = gaussrankscaler.fit_transform(X_train['CRIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankgaussscaler = RankGaussScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "x = rankgaussscaler.fit_transform(X_train['CRIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(X, columns=None, deep=False):\n",
    "    \"\"\"\n",
    "    Unite data into a DataFrame.\n",
    "    Objects that do not contain column names take the names from the argument.\n",
    "    Optionally perform deep copy of the data.\n",
    "    \"\"\"\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = pd.DataFrame(X, copy=deep)\n",
    "        else:\n",
    "            if columns is not None and np.size(X,1) != len(columns):\n",
    "                raise ValueError('The count of the column names does not correspond to the count of the columns')\n",
    "            if isinstance(X, list):\n",
    "                X = pd.DataFrame(X, columns=columns, copy=deep)  # lists are always copied, but for consistency, we still pass the argument\n",
    "            elif isinstance(X, (np.generic, np.ndarray)):\n",
    "                X = pd.DataFrame(X, columns=columns, copy=deep)\n",
    "            elif isinstance(X, csr_matrix):\n",
    "                X = pd.DataFrame(X.todense(), columns=columns, copy=deep)\n",
    "            else:\n",
    "                raise ValueError('Unexpected input type: %s' % (str(type(X))))\n",
    "\n",
    "            X = X.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "    elif deep:\n",
    "        X = X.copy(deep=True)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.all_classes_ = None\n",
    "        self.all_encoders_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit encoder according to X and y.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "        # first check the type\n",
    "        X = convert_input(X)\n",
    "        \n",
    "        self._dim = X.shape[1]\n",
    "\n",
    "        # if columns aren't passed, just use every string column\n",
    "        if self.cols is None:\n",
    "            self.cols = util.get_obj_cols(X)\n",
    "        else:\n",
    "            self.cols = util.convert_cols_to_list(self.cols)\n",
    "        \n",
    "        if self.handle_missing == 'error':\n",
    "            if X[self.cols].isnull().any().bool():\n",
    "                raise ValueError('Columns to be encoded can not contain null')\n",
    "        \n",
    "        n = len(self.columns)\n",
    "        self.all_classes_ = np.ndarray(shape=(n, ), dtype=object)\n",
    "        self.all_encoders_ = np.ndarray(shape=(n, ), dtype=object)\n",
    "        for i, column in enumerate(self.columns):\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, column].astype('str', copy=False))\n",
    "            classes = le.classes_.tolist()\n",
    "            bisect.insort_left(classes, '<unknown>')\n",
    "            le.classes_ = classes\n",
    "            self.all_classes_[i] = (column, np.array(le.classes_, dtype=object))\n",
    "            self.all_encoders_[i] = le\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for i, column in enumerate(self.columns):\n",
    "            X[:, column].astype('str')\n",
    "            X[:, column] = np.where(np.isin(X[:, column], self.all_classes_[i][1]), X[:, column], '<unknown>')\n",
    "            X[:, column] = self.all_encoders_[i].transform(X[:, column])\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        for i, column in enumerate(self.columns):\n",
    "            X[:, column] = self.all_encoders_[i].inverse_transform(X[:, column])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use target encoding to encode two categorical features\n",
    "enc = MultiColumnLabelEncoder()\n",
    "enc.fit(X_train[['CHAS', 'RAD']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the datasets\n",
    "training_numeric_dataset = enc.transform(X_train, y_train)\n",
    "testing_numeric_dataset = enc.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
