{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_preprocessing.gauss_rank_scaler import *\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunch = load_boston()\n",
    "\n",
    "y_train = bunch.target[:250]\n",
    "y_test = bunch.target[250:]\n",
    "\n",
    "X_train = pd.DataFrame(bunch.data[:250], columns=bunch.feature_names)\n",
    "X_test = pd.DataFrame(bunch.data[250:], columns=bunch.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_rank_scaler = GuassRankScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X_train[['CRIM', 'RM', 'AGE', 'DIS', 'B', 'LSTAT']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class GuassRankScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Standardize features by removing the mean and scaling to unit variance\n",
    "        The standard score of a sample `x` is calculated as:\n",
    "            z = (x - u) / s\n",
    "        where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
    "        and `s` is the standard deviation of the training samples or one if\n",
    "        `with_std=False`.\n",
    "        Centering and scaling happen independently on each feature by computing\n",
    "        the relevant statistics on the samples in the training set. Mean and\n",
    "        standard deviation are then stored to be used on later data using the\n",
    "        `transform` method.\n",
    "        Standardization of a dataset is a common requirement for many\n",
    "        machine learning estimators: they might behave badly if the\n",
    "        individual features do not more or less look like standard normally\n",
    "        distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
    "        For instance many elements used in the objective function of\n",
    "        a learning algorithm (such as the RBF kernel of Support Vector\n",
    "        Machines or the L1 and L2 regularizers of linear models) assume that\n",
    "        all features are centered around 0 and have variance in the same\n",
    "        order. If a feature has a variance that is orders of magnitude larger\n",
    "        that others, it might dominate the objective function and make the\n",
    "        estimator unable to learn from other features correctly as expected.\n",
    "        This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
    "        `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
    "        Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        copy : boolean, optional, default True\n",
    "            If False, try to avoid a copy and do inplace scaling instead.\n",
    "            This is not guaranteed to always work inplace; e.g. if the data is\n",
    "            not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
    "            returned.\n",
    "        with_mean : boolean, True by default\n",
    "            If True, center the data before scaling.\n",
    "            This does not work (and will raise an exception) when attempted on\n",
    "            sparse matrices, because centering them entails building a dense\n",
    "            matrix which in common use cases is likely to be too large to fit in\n",
    "            memory.\n",
    "        with_std : boolean, True by default\n",
    "            If True, scale the data to unit variance (or equivalently,\n",
    "            unit standard deviation).\n",
    "        Attributes\n",
    "        ----------\n",
    "        scale_ : ndarray or None, shape (n_features,)\n",
    "            Per feature relative scaling of the data. This is calculated using\n",
    "            `np.sqrt(var_)`. Equal to ``None`` when ``with_std=False``.\n",
    "            .. versionadded:: 0.17\n",
    "               *scale_*\n",
    "        mean_ : ndarray or None, shape (n_features,)\n",
    "            The mean value for each feature in the training set.\n",
    "            Equal to ``None`` when ``with_mean=False``.\n",
    "        var_ : ndarray or None, shape (n_features,)\n",
    "            The variance for each feature in the training set. Used to compute\n",
    "            `scale_`. Equal to ``None`` when ``with_std=False``.\n",
    "        n_samples_seen_ : int or array, shape (n_features,)\n",
    "            The number of samples processed by the estimator for each feature.\n",
    "            If there are not missing samples, the ``n_samples_seen`` will be an\n",
    "            integer, otherwise it will be an array.\n",
    "            Will be reset on new calls to fit, but increments across\n",
    "            ``partial_fit`` calls.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-4, copy=True, n_jobs=None, interp_kind='linear', interp_copy=False):\n",
    "        self.epsilon = epsilon\n",
    "        self.copy = copy\n",
    "        self.interp_params = {'kind': interp_kind, 'copy': interp_copy, 'fill_value': 'extrapolate'}\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute the mean and std to be used for later scaling.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to compute the mean and standard deviation\n",
    "            used for later scaling along the features axis.\n",
    "        y\n",
    "            Ignored\n",
    "        \"\"\"\n",
    "        X = check_array(X, copy=self.copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        ranks = np.argsort(np.argsort(X, axis=0), axis=0)\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factors = np.max(ranks) / 2.0 * bound\n",
    "        scaled_ranks = np.clip(ranks / factors - bound, -bound, bound)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._fit)(x) for x in X.T)\n",
    "        return self\n",
    "    \n",
    "    def _fit(self, x):\n",
    "        x = self.drop_duplicates(x)\n",
    "        rank = np.argsort(np.argsort(x))\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factor = np.max(rank) / 2.0 * bound\n",
    "        scaled_rank = np.clip(rank / factor - bound, -bound, bound)\n",
    "        return interp1d(x, scaled_rank, **self.interp_params)\n",
    "        \n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Perform standardization by centering and scaling\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Scale back the data to the original representation\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, **self.interp_params)\n",
    "        return inv_interp_func(erf(x))\n",
    "    \n",
    "    def drop_duplicates(self, x):\n",
    "        m = np.zeros_like(x, dtype=bool)\n",
    "        m[np.unique(x, return_index=True)[1]] = True\n",
    "        return x[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(x):\n",
    "    m = np.zeros_like(x, dtype=bool)\n",
    "    m[np.unique(x, return_index=True)[1]] = True\n",
    "    return x[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 1, 3, 3, 3, 0])\n",
    "m = np.zeros_like(a, dtype=bool)\n",
    "m[np.unique(a, return_index=True)[1]] = True\n",
    "a[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a, return_index=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_rank_scaler = GuassRankScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = drop_duplicates(X_train['ZN'])\n",
    "rank = np.argsort(np.argsort(x))\n",
    "bound = 1.0 - 0.0001\n",
    "factor = np.max(rank) / 2.0 * bound\n",
    "scaled_rank = np.clip(rank / factor - bound, -bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gauss_rank_scaler.fit_transform(X_train[['CRIM', 'ZN', 'RM', 'AGE', 'DIS', 'B', 'LSTAT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort([1.0, 3.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfinv\n",
    "\n",
    "class GaussRankScaler():\n",
    "\n",
    "\tdef __init__( self ):\n",
    "\t\tself.epsilon = 0.001\n",
    "\t\tself.lower = -1 + self.epsilon\n",
    "\t\tself.upper =  1 - self.epsilon\n",
    "\t\tself.range = self.upper - self.lower\n",
    "\n",
    "\tdef fit_transform( self, X ):\n",
    "\t\n",
    "\t\ti = np.argsort( X, axis = 0 )\n",
    "\t\tj = np.argsort( i, axis = 0 )\n",
    "\n",
    "\t\tassert ( j.min() == 0 ).all()\n",
    "\t\tassert ( j.max() == len( j ) - 1 ).all()\n",
    "\t\t\n",
    "\t\tj_range = len( j ) - 1\n",
    "\t\tself.divider = j_range / self.range\n",
    "\t\t\n",
    "\t\ttransformed = j / self.divider\n",
    "\t\ttransformed = transformed - self.upper\n",
    "\t\ttransformed = erfinv( transformed )\n",
    "\t\t\n",
    "\t\treturn transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rankgauss_trafo(x):\n",
    "    finite_indices = np.isfinite(x)\n",
    "    if np.sum(finite_indices) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    x_finite = x[np.isfinite(x)]\n",
    " \n",
    "    hist = dict()\n",
    "    for val in x_finite:\n",
    "        hist[val] = hist.get(val, 0) + 1\n",
    " \n",
    "    len_hist = len(hist)\n",
    "    list_keys = list(hist.keys())\n",
    " \n",
    "    if len_hist == 1:\n",
    "        return np.array(list_keys), np.array([0.0])\n",
    "    elif len_hist == 2:\n",
    "        return np.array(list_keys), np.array([0.0, 1.0])\n",
    "    else:\n",
    "        hist = OrderedDict(sorted(hist.items()))    # sort by key\n",
    "        n = float(x_finite.shape[0])\n",
    "        cnt = 0.0\n",
    "        mean = 0.0\n",
    "        trafo_keys = list()\n",
    "        trafo_values = list()\n",
    " \n",
    "        for key, val in hist.items():\n",
    "            # (notice) 'cnt / n * 0.998 + 1e-3' is always larger than zero\n",
    "            rank_v = norm_cdf_inv(cnt / n * 0.998 + 1e-3) * 0.7\n",
    "            trafo_keys.append(key)\n",
    "            trafo_values.append(rank_v)\n",
    "            mean += val * rank_v\n",
    "            cnt += val\n",
    " \n",
    "        mean /= n\n",
    "        trafo_values = np.array(trafo_values)\n",
    "        trafo_values -= mean\n",
    " \n",
    "        return np.array(trafo_keys), trafo_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "\n",
    "\n",
    "class GuassRankScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, epsilon=1e-4, kind='linear', copy=False, n_jobs=None):\n",
    "        self.epsilon = epsilon\n",
    "        self.interp_params = {'kind': kind, 'copy': copy, 'fill_value': 'extrapolate'}\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = check_array(X, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        ranks = np.argsort(np.argsort(X, axis=0), axis=0)\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factors = np.max(ranks) / 2.0 * bound\n",
    "        scaled_ranks = np.clip(ranks / factors - bound, -bound, bound)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(interp1d)(x, r, **self.interp_params) for x, r in zip(X.T, scaled_ranks.T))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "        X = check_array(X, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "        X = check_array(X, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, **self.interp_params)\n",
    "        return inv_interp_func(erf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GuassRankScaler(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_train[['CRIM', 'RM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = check_array(X_tr, dtype=FLOAT_DTYPES, force_all_finite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = np.argsort(np.argsort(X_v, axis=0), axis=0)\n",
    "bound = 1.0 - 0.0001\n",
    "factors = np.max(ranks) / 2.0 * bound\n",
    "scaled_ranks = np.clip(ranks / factors - bound, -bound, bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for x, r in zip(X_v.T, scaled_ranks.T):\n",
    "    a.append(interp1d(x, r, **interp_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_params = {'kind': 'linear', 'copy': False, 'fill_value': 'extrapolate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func_ = Parallel(n_jobs=None)(\n",
    "    delayed(interp1d)(x, r, **interp_params) for x, r in (X_v.T, scaled_ranks.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform(i, x):\n",
    "    return interp_func_[i](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func_[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=None)(delayed(_transform)(i, x) for i, x in enumerate(X_v.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.interp_func_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = np.argsort(np.argsort(X_tr, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bound = 1.0 - 0.001\n",
    "factor = np.max(ranks) / 2.0 * bound\n",
    "scaled_ranks = np.clip(ranks / factor - bound, -bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = [(x, y) for x, y in (X_tr.values.T, scaled_ranks.values.T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func = interp1d(X_tr, scaled_ranks, kind='linear', fill_value='extrapolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_func.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = interp_func(X_train['CRIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = scaler.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CRIM'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(z).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = scaler.fit_transform(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(vv[:, 0]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CRIM'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(v).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CRIM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(v.shape[0])[~np.isfinite(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = a[a != np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = scaler.inverse_transform(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import FLOAT_DTYPES, check_is_fitted\n",
    "from sklearn.utils import check_array, check_random_state\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import OrderedDict\n",
    "from numba import jit\n",
    " \n",
    " \n",
    "try:\n",
    "    from joblib import Parallel, delayed\n",
    "except ImportError:\n",
    "    from sklearn.externals.joblib import Parallel, delayed\n",
    " \n",
    " \n",
    "class RankGaussScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nan_to_val=None, extrapolate=False, num_storing=None,\n",
    "                 random_state=None, interp_params=None, n_jobs=None):\n",
    "        nan_to_val = nan_to_val or True\n",
    "        self.nan_to_val = 0.0 if isinstance(nan_to_val, bool) else nan_to_val\n",
    "        self.force_all_finite = False\n",
    "        if isinstance(nan_to_val, bool) and not nan_to_val:\n",
    "            self.force_all_finite = True\n",
    " \n",
    "        self.extrapolate = extrapolate\n",
    "        num_storing = num_storing or np.iinfo(int).max\n",
    "        self.num_storing = 2 if num_storing < 2 else num_storing\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.interp_params = interp_params or dict(kind='linear')\n",
    "        self.n_jobs = n_jobs\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        X = self._check_array(X)\n",
    "        X = self._to_2d_if_1d(X)\n",
    " \n",
    "        self.codebooks_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._make_codebook)(*x) for x in enumerate(X.T))\n",
    " \n",
    "        return self\n",
    " \n",
    "    def transform(self, X):\n",
    "        transformed = self._transform(X, self._transform_column)\n",
    "        if not self.force_all_finite:\n",
    "            transformed[~np.isfinite(transformed)] = self.nan_to_val\n",
    "        return transformed\n",
    " \n",
    "    def inverse_transform(self, X):\n",
    "        return self._transform(X, self._inv_transform_column)\n",
    " \n",
    "    def _transform(self, X, func_transform):\n",
    "        X = self._check_before_transform(X)\n",
    "        return_as_1d = True if len(X.shape) == 1 else False\n",
    "        X = self._to_2d_if_1d(X)\n",
    " \n",
    "        transformed = np.array(\n",
    "            Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(func_transform)(*x, **self.interp_params)\n",
    "                for x in enumerate(X.T))).T\n",
    " \n",
    "        return self._to_1d_if_single(transformed) if return_as_1d \\\n",
    "            else transformed    # preserve input shape\n",
    " \n",
    "    def _check_array(self, X):\n",
    "        # validate input and return X as numpy format\n",
    "        return check_array(X, dtype=FLOAT_DTYPES, ensure_2d=False,\n",
    "                           force_all_finite=self.force_all_finite)\n",
    " \n",
    "    def _check_num_cols(self, X):\n",
    "        # validate input after fit()\n",
    "        num_features = 1 if len(X.shape) == 1 else X.shape[1]\n",
    "        if num_features != len(self.codebooks_):\n",
    "            raise ValueError('bad input shape {0}'.format(X.shape))\n",
    " \n",
    "    def _check_before_transform(self, X):\n",
    "        check_is_fitted(self, 'codebooks_')    # check if 'codebooks_' exists\n",
    "        X = self._check_array(X)       # check input type and structure\n",
    "        self._check_num_cols(X)        # check # of columns\n",
    "        return X\n",
    " \n",
    "    def _make_codebook(self, col_index, x):\n",
    "        codebook = build_rankgauss_trafo(x)\n",
    "        num_codes = len(codebook[0])\n",
    " \n",
    "        if num_codes == 0:\n",
    "            raise ValueError('column %d contains only null values' % col_index)\n",
    "        elif num_codes > self.num_storing:\n",
    "            # first, select minimum and maximum, then choose the rest randomly\n",
    "            chosen = self.random_state.choice(\n",
    "                num_codes - 2, self.num_storing - 2, replace=False)\n",
    "            chosen = np.append(np.array([0, num_codes - 1]), chosen + 1)\n",
    "            return codebook[0][chosen], codebook[1][chosen]\n",
    "        else:\n",
    "            return codebook\n",
    " \n",
    "    def _transform_column(self, index, x, **interp1d_params):\n",
    "        return self._transform_with_interp(\n",
    "            x, *self.codebooks_[index], **interp1d_params)\n",
    " \n",
    "    def _inv_transform_column(self, index, x, **interp1d_params):\n",
    "        return self._transform_with_interp(\n",
    "            x, *reversed(self.codebooks_[index]), **interp1d_params)\n",
    " \n",
    "    def _transform_with_interp(self, x, train_x, train_y, **interp1d_params):\n",
    "        if len(train_x) == 1:\n",
    "            return np.ones(x.shape) * train_y[0]\n",
    "        f = interp1d(train_x, train_y, fill_value='extrapolate',\n",
    "                     **interp1d_params)\n",
    "        return f(x) if self.extrapolate else f(np.clip(x, *minmax(train_x)))\n",
    " \n",
    "    @staticmethod\n",
    "    def _to_2d_if_1d(a):\n",
    "        return a.reshape(-1, 1) if len(a.shape) == 1 else a\n",
    " \n",
    "    @staticmethod\n",
    "    def _to_1d_if_single(a):\n",
    "        return a.ravel() if a.shape[1] == 1 else a\n",
    " \n",
    " \n",
    "# function for simultaneous max() and min() (using numba)\n",
    "# https://stackoverflow.com/a/33919126\n",
    "@jit\n",
    "def minmax(x):\n",
    "    maximum = x[0]\n",
    "    minimum = x[0]\n",
    "    for i in x[1:]:\n",
    "        if i > maximum:\n",
    "            maximum = i\n",
    "        elif i < minimum:\n",
    "            minimum = i\n",
    "    return minimum, maximum\n",
    " \n",
    " \n",
    "# converted from [ref 1]\n",
    "@jit\n",
    "def norm_cdf_inv(p):\n",
    "    sign = 1.0\n",
    "    if p < 0.5:\n",
    "        sign = -1.0\n",
    "    else:\n",
    "        p = 1.0 - p\n",
    "    t = np.sqrt(-2.0 * np.log(p))\n",
    "    return sign * (t - ((0.010328 * t + 0.802853) * t + 2.515517) /\n",
    "                   (((0.001308 * t + 0.189269) * t + 1.432788) * t + 1.0))\n",
    " \n",
    " \n",
    "# converted from [ref 1]\n",
    "@jit\n",
    "def build_rankgauss_trafo(x):\n",
    "    finite_indices = np.isfinite(x)\n",
    "    if np.sum(finite_indices) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    x_finite = x[np.isfinite(x)]\n",
    " \n",
    "    hist = dict()\n",
    "    for val in x_finite:\n",
    "        hist[val] = hist.get(val, 0) + 1\n",
    " \n",
    "    len_hist = len(hist)\n",
    "    list_keys = list(hist.keys())\n",
    " \n",
    "    if len_hist == 1:\n",
    "        return np.array(list_keys), np.array([0.0])\n",
    "    elif len_hist == 2:\n",
    "        return np.array(list_keys), np.array([0.0, 1.0])\n",
    "    else:\n",
    "        hist = OrderedDict(sorted(hist.items()))    # sort by key\n",
    "        n = float(x_finite.shape[0])\n",
    "        cnt = 0.0\n",
    "        mean = 0.0\n",
    "        trafo_keys = list()\n",
    "        trafo_values = list()\n",
    " \n",
    "        for key, val in hist.items():\n",
    "            # (notice) 'cnt / n * 0.998 + 1e-3' is always larger than zero\n",
    "            rank_v = norm_cdf_inv(cnt / n * 0.998 + 1e-3) * 0.7\n",
    "            trafo_keys.append(key)\n",
    "            trafo_values.append(rank_v)\n",
    "            mean += val * rank_v\n",
    "            cnt += val\n",
    " \n",
    "        mean /= n\n",
    "        trafo_values = np.array(trafo_values)\n",
    "        trafo_values -= mean\n",
    " \n",
    "        return np.array(trafo_keys), trafo_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussrankscaler = GaussRankScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "v = gaussrankscaler.fit_transform(X_train['CRIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankgaussscaler = RankGaussScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "x = rankgaussscaler.fit_transform(X_train['CRIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(X, columns=None, deep=False):\n",
    "    \"\"\"\n",
    "    Unite data into a DataFrame.\n",
    "    Objects that do not contain column names take the names from the argument.\n",
    "    Optionally perform deep copy of the data.\n",
    "    \"\"\"\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = pd.DataFrame(X, copy=deep)\n",
    "        else:\n",
    "            if columns is not None and np.size(X,1) != len(columns):\n",
    "                raise ValueError('The count of the column names does not correspond to the count of the columns')\n",
    "            if isinstance(X, list):\n",
    "                X = pd.DataFrame(X, columns=columns, copy=deep)  # lists are always copied, but for consistency, we still pass the argument\n",
    "            elif isinstance(X, (np.generic, np.ndarray)):\n",
    "                X = pd.DataFrame(X, columns=columns, copy=deep)\n",
    "            elif isinstance(X, csr_matrix):\n",
    "                X = pd.DataFrame(X.todense(), columns=columns, copy=deep)\n",
    "            else:\n",
    "                raise ValueError('Unexpected input type: %s' % (str(type(X))))\n",
    "\n",
    "            X = X.apply(lambda x: pd.to_numeric(x, errors='ignore'))\n",
    "    elif deep:\n",
    "        X = X.copy(deep=True)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.all_classes_ = None\n",
    "        self.all_encoders_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit encoder according to X and y.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "        # first check the type\n",
    "        X = convert_input(X)\n",
    "        \n",
    "        self._dim = X.shape[1]\n",
    "\n",
    "        # if columns aren't passed, just use every string column\n",
    "        if self.cols is None:\n",
    "            self.cols = util.get_obj_cols(X)\n",
    "        else:\n",
    "            self.cols = util.convert_cols_to_list(self.cols)\n",
    "        \n",
    "        if self.handle_missing == 'error':\n",
    "            if X[self.cols].isnull().any().bool():\n",
    "                raise ValueError('Columns to be encoded can not contain null')\n",
    "        \n",
    "        n = len(self.columns)\n",
    "        self.all_classes_ = np.ndarray(shape=(n, ), dtype=object)\n",
    "        self.all_encoders_ = np.ndarray(shape=(n, ), dtype=object)\n",
    "        for i, column in enumerate(self.columns):\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, column].astype('str', copy=False))\n",
    "            classes = le.classes_.tolist()\n",
    "            bisect.insort_left(classes, '<unknown>')\n",
    "            le.classes_ = classes\n",
    "            self.all_classes_[i] = (column, np.array(le.classes_, dtype=object))\n",
    "            self.all_encoders_[i] = le\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for i, column in enumerate(self.columns):\n",
    "            X[:, column].astype('str')\n",
    "            X[:, column] = np.where(np.isin(X[:, column], self.all_classes_[i][1]), X[:, column], '<unknown>')\n",
    "            X[:, column] = self.all_encoders_[i].transform(X[:, column])\n",
    "        return X\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        for i, column in enumerate(self.columns):\n",
    "            X[:, column] = self.all_encoders_[i].inverse_transform(X[:, column])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use target encoding to encode two categorical features\n",
    "enc = MultiColumnLabelEncoder()\n",
    "enc.fit(X_train[['CHAS', 'RAD']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the datasets\n",
    "training_numeric_dataset = enc.transform(X_train, y_train)\n",
    "testing_numeric_dataset = enc.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
